{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support\n",
    "# csv to pd loader\n",
    "import corelib.data_loader as data_loader\n",
    "\n",
    "# reduce memory usage\n",
    "import corelib.data_prep as data_prep\n",
    "\n",
    "# dump data with\n",
    "import corelib.data_dump as data_dump\n",
    "\n",
    "# saving images\n",
    "import corelib.data_vis as data_vis\n",
    "# for ignoring SciPy warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(data_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(data_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.woe import WOEEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.sum_coding import SumEncoder\n",
    "from category_encoders.backward_difference import BackwardDifferenceEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.helmert import HelmertEncoder\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "from category_encoders.james_stein import JamesSteinEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.hashing import HashingEncoder\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.polynomial import PolynomialEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dump from this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Unpack data, view .csv files or return pandas dataframe\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    :param mode:\n",
      "    Mode of function. \n",
      "    Available:\n",
      "    'tree' show  available files\n",
      "    'view' show first five strings of data files\n",
      "    'extract' extract data into dict of objects\n",
      "        string\n",
      "\n",
      "    :param path:\n",
      "    Current path to folder with data\n",
      "        string, default DATA_PATH\n",
      "\n",
      "    :param data_for_load:\n",
      "    Dictionary where keys are file names and values are dicts of parameters.\n",
      "    Looks like {'this.csv': {'sep': ',', 'encoding': 'utf-8'}} etc.\n",
      "    If None all files are loaded wit default parameters.\n",
      "        dict, default None\n",
      "\n",
      "    Parameters are available:\n",
      "\n",
      "    :sep:\n",
      "    Delimiter to use\n",
      "        string, default ','\n",
      "\n",
      "    :index_col:\n",
      "    Column to use as the row labels of the DataFrame, either given as string name or column index.\n",
      "    If a sequence of int/str is given, a MultiIndex is used.\n",
      "    Note: index_col=False can be used to force pandas to not use the first column as the index, e.g. when \n",
      "    you have a malformed file with delimiters at the end of each line.\n",
      "        int, str, sequence of int/str, or False, default None\n",
      "\n",
      "    :dtype: Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’}\n",
      "    Use str or object together with suitable na_values settings to preserve and not interpret dtype.\n",
      "    If converters are specified, they will be applied INSTEAD of dtype conversion\n",
      "    As example looks like 'dtype': {'assigned_day': np.float64}\n",
      "        dict, default None\n",
      "\n",
      "    :encoding: Encoding to - use for UTF when reading/writing (ex. ‘utf-8’)\n",
      "        str, default None\n",
      "\n",
      "    :parse_dates:\n",
      "    Parse column as datetime format\n",
      "    If True -> try parsing the index.\n",
      "    List of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column.\n",
      "    List of lists. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column.\n",
      "    Dict, e.g. {‘foo’ : [1, 3]} -> parse columns 1, 3 as date and call result ‘foo’\n",
      "    More information [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
      "    If a column or index cannot be represented as an array of datetimes, \n",
      "    say because of an unparseable value or a mixture of timezones, the column \n",
      "    or index will be returned unaltered as an object data type.\n",
      "        bool or list of int or names or list of lists or dict, default False\n",
      "\n",
      "    Return\n",
      "    ------\n",
      "    For mode 'extract' dict with pandas dataframe objects\n",
      "\n",
      "    Future\n",
      "    ------\n",
      "    - Code/decode checking for .zip (python-3.5+ dont support encoding in subprocess)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(data_loader.loader.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anydata.csv ..... C:\\xampp\\htdocs\\_uroki_\\python-learning\\ml_support\\input\\notempty\\anydata.csv\n",
      "most_deeped.txt ..... C:\\xampp\\htdocs\\_uroki_\\python-learning\\ml_support\\input\\notempty\\notempty_deeper\\most_deeped.txt\n",
      "sample.csv ..... C:\\xampp\\htdocs\\_uroki_\\python-learning\\ml_support\\input\\sample.csv\n",
      "samplezip.zip ..... C:\\xampp\\htdocs\\_uroki_\\python-learning\\ml_support\\input\\samplezip.zip\n"
     ]
    }
   ],
   "source": [
    "data_loader.loader(mode='tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five lines of viewed files:\n",
      "\n",
      "anydata.csv\n",
      "-----\n",
      "installation_id,event_id,game_session,timestamp,event_data,event_count,event_code,game_time,title,type,world\n",
      "0001e90f,27253bdc,45bb1e1b6b50c07b,2019-09-06T17:53:46.937Z,\"{\"\"event_code\"\": 2000, \"\"event_count\"\": 1}\",1,2000,0,Welcome to Lost Lagoon!,Clip,NONE\n",
      "0001e90f,27253bdc,17eeb7f223665f53,2019-09-06T17:54:17.519Z,\"{\"\"event_code\"\": 2000, \"\"event_count\"\": 1}\",1,2000,0,Magma Peak - Level 1,Clip,MAGMAPEAK\n",
      "0001e90f,77261ab5,0848ef14a8dc6892,2019-09-06T17:54:56.302Z,\"{\"\"version\"\":\"\"1.0\"\",\"\"event_count\"\":1,\"\"game_time\"\":0,\"\"event_code\"\":2000}\",1,2000,0,Sandcastle Builder (Activity),Activity,MAGMAPEAK\n",
      "0001e90f,b2dba42b,0848ef14a8dc6892,2019-09-06T17:54:56.387Z,\"{\"\"description\"\":\"\"Let's build a sandcastle! First, fill up your mold with sand! You can use the shovel here. The mold gives the sand its shape!\"\",\"\"identifier\"\":\"\"Dot_LetsSandcastle,Dot_FillMold,Dot_MoldShape\"\",\"\"media_type\"\":\"\"audio\"\",\"\"total_duration\"\":6758,\"\"event_count\"\":2,\"\"game_time\"\":53,\"\"event_code\"\":3010}\",2,3010,53,Sandcastle Builder (Activity),Activity,MAGMAPEAK\n",
      "0001e90f,1bb5fbdb,0848ef14a8dc6892,2019-09-06T17:55:03.253Z,\"{\"\"description\"\":\"\"Let's build a sandcastle! First, fill up your mold with sand! You can use the shovel here. The mold gives the sand its shape!\"\",\"\"identifier\"\":\"\"Dot_LetsSandcastle,Dot_FillMold,Dot_MoldShape\"\",\"\"media_type\"\":\"\"audio\"\",\"\"duration\"\":6919,\"\"event_count\"\":3,\"\"game_time\"\":6972,\"\"event_code\"\":3110}\",3,3110,6972,Sandcastle Builder (Activity),Activity,MAGMAPEAK\n",
      "\n",
      "sample.csv\n",
      "-----\n",
      "family_id,assigned_day\n",
      "0,100\n",
      "1,99\n",
      "2,98\n",
      "3,97\n",
      "4,96\n",
      "\n",
      "samplezip.zip\n",
      "-----\n",
      "family_id,assigned_day\n",
      "0,100\n",
      "1,99\n",
      "2,98\n",
      "3,97\n",
      "4,96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader.loader(mode='view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of extracted files:\n",
      "anydata.csv\n",
      "sample.csv\n",
      "samplezip.zip\n"
     ]
    }
   ],
   "source": [
    "data = data_loader.loader(mode='extract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of extracted files:\n",
      "sample.csv\n"
     ]
    }
   ],
   "source": [
    "data_seq1 = data_loader.loader(mode='extract', data_for_load={'sample.csv':{}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of extracted files:\n",
      "samplezip.zip\n",
      "anydata.csv\n"
     ]
    }
   ],
   "source": [
    "data_for_load = {'samplezip.zip': \n",
    "                 {'index_col': 'family_id', \n",
    "                  'dtype': {'assigned_day': np.float64}},\n",
    "                'anydata.csv':\n",
    "                {'parse_dates': ['timestamp']}}\n",
    "data_seq2 = data_loader.loader(mode='extract', data_for_load=data_for_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>installation_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>game_session</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>event_data</th>\n",
       "      <th>event_count</th>\n",
       "      <th>event_code</th>\n",
       "      <th>game_time</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001e90f</td>\n",
       "      <td>27253bdc</td>\n",
       "      <td>45bb1e1b6b50c07b</td>\n",
       "      <td>2019-09-06 17:53:46.937</td>\n",
       "      <td>{\"event_code\": 2000, \"event_count\": 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>Welcome to Lost Lagoon!</td>\n",
       "      <td>Clip</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  installation_id  event_id      game_session               timestamp  \\\n",
       "0        0001e90f  27253bdc  45bb1e1b6b50c07b 2019-09-06 17:53:46.937   \n",
       "\n",
       "                               event_data  event_count  event_code  game_time  \\\n",
       "0  {\"event_code\": 2000, \"event_count\": 1}            1        2000          0   \n",
       "\n",
       "                     title  type world  \n",
       "0  Welcome to Lost Lagoon!  Clip  NONE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_seq2['anydata.csv'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = data_seq2.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, data_seq1, data_seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.00 Mb (37.5% reduction)\n",
      "Mem. usage decreased to 13.73 Mb (18.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "# reduce memory usage\n",
    "df_train = data_prep.reduce_mem_usage(df_train)\n",
    "df_test = data_prep.reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 0 is dumped to \"loaded_data\" objects\n",
      "Object 1 is dumped to \"loaded_data\" objects\n"
     ]
    }
   ],
   "source": [
    "# Dump loaded and prepared data\n",
    "data_dump.dumper(dump_list=data, path='loaded_data', method='shelve', task='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump open (prepared dataset)\n",
    "df_train, df_test = data_dump.dumper(path='loaded_data', method='shelve', task='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.hist(bins=50, figsize=(10,6))\n",
    "data_vis.save_fig(\"df_train_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an features from data to plot scatter_matrix\n",
    "attributes = []\n",
    "scatter_matrix(df_train[attributes], figsize=(12, 8))\n",
    "data_vis.save_fig(\"df_train_correlation_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing pipline\n",
    "pipePre = Pipeline([\n",
    "    ('standardscaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer())\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pipePre.fit_transform(df_train)\n",
    "df_test = pipePre.fit_transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size = 0.25, random_state=42)\n",
    "N_train, _ = X_train.shape \n",
    "N_test,  _ = X_test.shape \n",
    "print(N_train, N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train\n",
    "del df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
