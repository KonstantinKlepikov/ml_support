{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support\n",
    "import corelib\n",
    "\n",
    "# csv to pd loader\n",
    "from corelib.data_loader import loader\n",
    "\n",
    "# reduce memory usage for pd-index\n",
    "from corelib.data_prep import reduce_mem_usage\n",
    "from corelib.data_prep import reduce_obj_mem_usage\n",
    "\n",
    "# searching for unical ordered values\n",
    "from corelib.data_prep import search_func\n",
    "\n",
    "#dump data with\n",
    "from corelib.data_dump import dumper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dump from this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Unpack kaggle data, view .csv files or return pandas dataframe\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "\n",
      "    :param mode:\n",
      "    Mode of function. Available 'extract' for extracting data into dict of objects\n",
      "    or 'view' for show first 5 strings of data files\n",
      "        string\n",
      "\n",
      "    :param path:\n",
      "    Current path to folder with data\n",
      "        string, default DATA_PATH constant\n",
      "\n",
      "    :param data_for_load:\n",
      "    Dict where keys are file names and values are dicts of parameters.\n",
      "    Looks like {'this.csv': {'sep': ',', 'coding': 'utf-8'}} etc.\n",
      "    If None all files are loaded wit default parameters.\n",
      "        dict, default None\n",
      "\n",
      "    For data_for_load parameters are available:\n",
      "\n",
      "    :sep:\n",
      "    Delimiter to use\n",
      "        string, default ','\n",
      "\n",
      "    :index_col:\n",
      "    Column to use as the row labels of the DataFrame,\n",
      "    either given as string name or column index.\n",
      "    If a sequence of int / str is given, a MultiIndex is used.\n",
      "    Note: index_col=False can be used to force pandas to not use the first column as the index, e.g. when \n",
      "    you have a malformed file with delimiters at the end of each line.\n",
      "        int, str, sequence of int / str, or False, default False\n",
      "\n",
      "    :dtype: Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’}\n",
      "    Use str or object together with suitable na_values settings to preserve and not interpret dtype.\n",
      "    If converters are specified, they will be applied INSTEAD of dtype conversion\n",
      "        dict, default None\n",
      "\n",
      "    :coding: Encoding to - use for UTF when reading/writing (ex. ‘utf-8’)\n",
      "        str, default None\n",
      "\n",
      "    Return\n",
      "    ------\n",
      "\n",
      "    Dict with pandas data frame objects for 'extract' mode or dict of None for 'view' mode\n",
      "\n",
      "    Future\n",
      "    ------\n",
      "\n",
      "    - rewrite extractor for checking different headers in different files\n",
      "    - Code/decode checking for .zip\n",
      "    - other formats\n",
      "    - time stamps converter\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(loader.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.csv ..... C:\\xampp\\htdocs\\_uroki_\\python-learning\\ml_support\\input\\sample.csv\n",
      "samplezip.zip ..... C:\\xampp\\htdocs\\_uroki_\\python-learning\\ml_support\\input\\samplezip.zip\n",
      "test.txt ..... C:\\xampp\\htdocs\\_uroki_\\python-learning\\ml_support\\input\\test_full\\test.txt\n"
     ]
    }
   ],
   "source": [
    "loader(mode='tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family_id,assigned_day\n",
      "0,100\n",
      "1,99\n",
      "2,98\n",
      "3,97\n",
      "4,96\n",
      "family_id,assigned_day\n",
      "0,100\n",
      "1,99\n",
      "2,98\n",
      "3,97\n",
      "4,96\n"
     ]
    }
   ],
   "source": [
    "loader(mode='view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sample'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = loader(mode='extract', index_col='family_id', dtype={'assigned_day': np.float64})\n",
    "data = loader(mode='extract', data_for_load={'sample.csv':{}})\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = data.values()\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce memory usage\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump loaded and prepared data\n",
    "dumper(dump_list=data, path='loaded_data', method='shelve', task='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump open (prepared dataset)\n",
    "df_train, df_test = dumper(path='loaded_data', method='shelve', task='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
