{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import os\n",
    "import sys\n",
    "import shelve \n",
    "import string\n",
    "import time\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support\n",
    "\n",
    "# csv to pd loader\n",
    "from corelib.utilities import loader\n",
    "\n",
    "# reduce memory usage for pd-index\n",
    "from corelib.utilities import reduce_mem_usage\n",
    "\n",
    "# searching for unical ordered values\n",
    "from corelib.utilities import search_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.woe import WOEEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.sum_coding import SumEncoder\n",
    "from category_encoders.backward_difference import BackwardDifferenceEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.helmert import HelmertEncoder\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "from category_encoders.james_stein import JamesSteinEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.hashing import HashingEncoder\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.polynomial import PolynomialEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double validation\n",
    "\n",
    "from typing import List\n",
    "class DoubleValidationEncoderNumerical:\n",
    "    \"\"\"\n",
    "    Encoder with validation within\n",
    "    \"\"\"\n",
    "    def __init__(self, cols: List, encoder, folds):\n",
    "        \"\"\"\n",
    "        :param cols: Categorical columns\n",
    "        :param encoder: Encoder class\n",
    "        :param folds: Folds to split the data\n",
    "        \"\"\"\n",
    "        self.cols = cols\n",
    "        self.encoder = encoder\n",
    "        self.encoders_dict = {}\n",
    "        self.folds = folds\n",
    "\n",
    "    def fit_transform(self, X: pd.DataFrame, y: np.array) -> pd.DataFrame:\n",
    "        X = X.reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        for n_fold, (train_idx, val_idx) in enumerate(self.folds.split(X, y)):\n",
    "            X_train, X_val = X.loc[train_idx].reset_index(drop=True), X.loc[val_idx].reset_index(drop=True)\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            _ = self.encoder.fit_transform(X_train, y_train)\n",
    "\n",
    "            # transform validation part and get all necessary cols\n",
    "            val_t = self.encoder.transform(X_val)\n",
    "\n",
    "            if n_fold == 0:\n",
    "                cols_representation = np.zeros((X.shape[0], val_t.shape[1]))\n",
    "            \n",
    "            self.encoders_dict[n_fold] = self.encoder\n",
    "\n",
    "            cols_representation[val_idx, :] += val_t.values\n",
    "\n",
    "        cols_representation = pd.DataFrame(cols_representation, columns=X.columns)\n",
    "\n",
    "        return cols_representation\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.reset_index(drop=True)\n",
    "\n",
    "        cols_representation = None\n",
    "\n",
    "        for encoder in self.encoders_dict.values():\n",
    "            test_tr = encoder.transform(X)\n",
    "\n",
    "            if cols_representation is None:\n",
    "                cols_representation = np.zeros(test_tr.shape)\n",
    "\n",
    "            cols_representation = cols_representation + test_tr / self.folds.n_splits\n",
    "\n",
    "        cols_representation = pd.DataFrame(cols_representation, columns=X.columns)\n",
    "        \n",
    "        return cols_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "\n",
    "data_path = os.path.realpath('../input')\n",
    "dump_path = os.path.realpath('../kernels/loaded_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dump from this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader(data_path)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x, df_train_y, df_test_x, df_test_y = data.values()\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump loaded and prepared data\n",
    "with shelve.open(dump_path) as s:\n",
    "    s[\"df_train\"] = df_train_x\n",
    "    s[\"df_test\"] = df_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x = reduce_mem_usage(df_train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump open (prepared dataset)\n",
    "with shelve.open(dump_path) as o:\n",
    "    df_train = o[\"df_train\"]\n",
    "    df_test = o[\"df_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing pipline\n",
    "pipePre = Pipeline([\n",
    "    ('simpleimputer', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)),\n",
    "    ('standardscaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer())\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x = pipePre.fit_transform(df_train_x)\n",
    "df_test_x = pipePre.fit_transform(df_test_x)\n",
    "del df_train_x\n",
    "del df_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train_x, df_train_y, test_size = 0.25, random_state=42)\n",
    "N_train, _ = X_train.shape \n",
    "N_test,  _ = X_test.shape \n",
    "print(N_train, N_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
